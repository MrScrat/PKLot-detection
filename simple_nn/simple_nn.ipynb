{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 11:10:28.309192: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.util import montage\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "import os\n",
    "import pdb\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../PKLot/PKLotSegmented_resized/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indexing train data\n",
      "indexing test data\n",
      "indexing validation data\n"
     ]
    }
   ],
   "source": [
    "# load train data\n",
    "print('indexing train data')\n",
    "train_img = []\n",
    "train_label = []\n",
    "for folder in os.listdir(path):\n",
    "    if folder[0] != '.':\n",
    "        for weather in os.listdir(os.path.join(path, folder)):\n",
    "            if weather[0] != '.':\n",
    "                for date in os.listdir(os.path.join(path, folder, weather))[:-4]:\n",
    "                    if date[0] != '.':\n",
    "                        for occupied in os.listdir(os.path.join(path, folder, weather, date)):\n",
    "                            if occupied[0] != '.':\n",
    "                                for img in os.listdir(os.path.join(path, folder, weather, date, occupied)):\n",
    "                                    train_label.append(occupied)\n",
    "                                    train_img.append(os.path.join(path, folder, weather, date, occupied, img))\n",
    "\n",
    "# load test data\n",
    "print('indexing test data')\n",
    "test_img = []\n",
    "test_label = []\n",
    "for folder in os.listdir(path):\n",
    "    if folder[0] != '.':\n",
    "        for weather in os.listdir(os.path.join(path, folder)):\n",
    "            if weather[0] != '.':\n",
    "                for date in os.listdir(os.path.join(path, folder, weather))[-4:-1]:\n",
    "                    if date[0] != '.':\n",
    "                        for occupied in os.listdir(os.path.join(path, folder, weather, date)):\n",
    "                            if occupied[0] != '.':\n",
    "                                for img in os.listdir(os.path.join(path, folder, weather, date, occupied)):\n",
    "                                    test_label.append(occupied)\n",
    "                                    test_img.append(os.path.join(path, folder, weather, date, occupied, img))\n",
    "\n",
    "# load validation data\n",
    "print('indexing validation data')\n",
    "valid_img = []\n",
    "valid_label = []\n",
    "for folder in os.listdir(path):\n",
    "    if folder[0] != '.':\n",
    "        for weather in os.listdir(os.path.join(path, folder)):\n",
    "            if weather[0] != '.':\n",
    "                for date in os.listdir(os.path.join(path, folder, weather))[-1:]:\n",
    "                    if date[0] != '.':\n",
    "                        for occupied in os.listdir(os.path.join(path, folder, weather, date)):\n",
    "                            if occupied[0] != '.':\n",
    "                                for img in os.listdir(os.path.join(path, folder, weather, date, occupied)):\n",
    "                                    valid_label.append(occupied)\n",
    "                                    valid_img.append(os.path.join(path, folder, weather, date, occupied, img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels to one hot\n",
    "numoutputs = len(np.unique(train_label))\n",
    "_, t = np.unique(train_label, return_inverse=True)\n",
    "t_train = to_categorical(t, numoutputs)\n",
    "\n",
    "_, t = np.unique(test_label, return_inverse=True)\n",
    "t_test = to_categorical(t, numoutputs)\n",
    "\n",
    "_, t = np.unique(valid_label, return_inverse=True)\n",
    "t_valid = to_categorical(t, numoutputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe to load with tf datagenerator\n",
    "train_df = pd.DataFrame(list(zip(train_img, t_train)), columns =['img_path', 'label'])\n",
    "test_df = pd.DataFrame(list(zip(test_img, t_test)), columns =['img_path', 'label'])\n",
    "valid_df = pd.DataFrame(list(zip(valid_img, t_valid)), columns =['img_path', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 489852 non-validated image filenames.\n",
      "Found 57115 non-validated image filenames.\n",
      "Found 148884 non-validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "img_size = (90, 90)\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "train_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=\"./\",\n",
    "    x_col=\"img_path\",\n",
    "    y_col=\"label\",\n",
    "    #subset=\"training\",\n",
    "    batch_size=1000,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"raw\",\n",
    "    target_size=img_size,\n",
    "    validate_filenames=False\n",
    "    )\n",
    "    \n",
    "valid_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=valid_df,\n",
    "    directory=\"./\",\n",
    "    x_col=\"img_path\",\n",
    "    y_col=\"label\",\n",
    "    #subset=\"training\",\n",
    "    batch_size=1000,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"raw\",\n",
    "    target_size=img_size,\n",
    "    validate_filenames=False\n",
    "    )\n",
    "\n",
    "# test_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "test_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=\"./\",\n",
    "    x_col=\"img_path\",\n",
    "    y_col=\"label\",\n",
    "    #subset=\"training\",\n",
    "    batch_size=1000,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"raw\",\n",
    "    target_size=img_size,\n",
    "    validate_filenames=False\n",
    "    )\n",
    "\n",
    "# fix for bug in keras with 'raw' input in datagenerators:\n",
    "# https://stackoverflow.com/questions/64978209/valueerror-when-trying-to-execute-model-fit-failed-to-convert-a-numpy-array/\n",
    "train_generator._targets = np.stack(train_generator._targets)\n",
    "valid_generator._targets = np.stack(valid_generator._targets)\n",
    "test_generator._targets = np.stack(test_generator._targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-08 16:58:35.791678: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 30000)             0         \n",
      "                                                                 \n",
      " hidden1 (Dense)             (None, 100)               3000100   \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,000,302\n",
      "Trainable params: 3,000,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create neural network\n",
    "model = Sequential()\n",
    "model.add(Input((*img_size, 3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=100, activation='relu', name='hidden1'))\n",
    "# model.add(Dense(units=100, activation='sigmoid', name='hidden2'))\n",
    "# model.add(Dense(units=50, activation='relu', name='hidden3'))\n",
    "# model.add(Dense(units=50, activation='relu', name='hidden4'))\n",
    "model.add(Dense(units=2, activation='softmax', name='output'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer= Adam(learning_rate=0.00001),\n",
    "    loss='mse',\n",
    "    metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490/490 [==============================] - ETA: 0s - loss: 0.0840 - accuracy: 0.9190\n",
      "Epoch 1: saving model to best_simple_nn_weights\n",
      "INFO:tensorflow:Assets written to: best_simple_nn_weights/assets\n",
      "490/490 [==============================] - 1373s 3s/step - loss: 0.0840 - accuracy: 0.9190 - val_loss: 0.0465 - val_accuracy: 0.9586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1674440a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"best_simple_nn_weights\", monitor='accuracy', verbose=1,\n",
    "    save_best_only=False, mode='auto')\n",
    "\n",
    "model.fit(train_generator, validation_data=valid_generator, callbacks=[checkpoint])\n",
    "# save weights\n",
    "model.save('simple_nn_weights2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 588s 4s/step - loss: 0.0363 - accuracy: 0.9720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0362788550555706, 0.9719849228858948]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('pklot')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "135e6675a82798f371aa95a542c2e675d1d47c136c7a33166cb3d7afadac973e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
