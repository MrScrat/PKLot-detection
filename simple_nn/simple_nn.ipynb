{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-08 16:58:16.781219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.util import montage\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "import os\n",
    "import pdb\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../PKLot/PKLotSegmented_resized/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indexing train data\n",
      "indexing test data\n",
      "indexing validation data\n"
     ]
    }
   ],
   "source": [
    "# load train data\n",
    "print('indexing train data')\n",
    "train_img = []\n",
    "train_label = []\n",
    "for folder in os.listdir(path):\n",
    "    if folder[0] != '.':\n",
    "        for weather in os.listdir(os.path.join(path, folder)):\n",
    "            if weather[0] != '.':\n",
    "                for date in os.listdir(os.path.join(path, folder, weather))[:-4]:\n",
    "                    if date[0] != '.':\n",
    "                        for occupied in os.listdir(os.path.join(path, folder, weather, date)):\n",
    "                            if occupied[0] != '.':\n",
    "                                for img in os.listdir(os.path.join(path, folder, weather, date, occupied)):\n",
    "                                    train_label.append(occupied)\n",
    "                                    train_img.append(os.path.join(path, folder, weather, date, occupied, img))\n",
    "\n",
    "# load test data\n",
    "print('indexing test data')\n",
    "test_img = []\n",
    "test_label = []\n",
    "for folder in os.listdir(path):\n",
    "    if folder[0] != '.':\n",
    "        for weather in os.listdir(os.path.join(path, folder)):\n",
    "            if weather[0] != '.':\n",
    "                for date in os.listdir(os.path.join(path, folder, weather))[-4:-1]:\n",
    "                    if date[0] != '.':\n",
    "                        for occupied in os.listdir(os.path.join(path, folder, weather, date)):\n",
    "                            if occupied[0] != '.':\n",
    "                                for img in os.listdir(os.path.join(path, folder, weather, date, occupied)):\n",
    "                                    test_label.append(occupied)\n",
    "                                    test_img.append(os.path.join(path, folder, weather, date, occupied, img))\n",
    "\n",
    "# load validation data\n",
    "print('indexing validation data')\n",
    "valid_img = []\n",
    "valid_label = []\n",
    "for folder in os.listdir(path):\n",
    "    if folder[0] != '.':\n",
    "        for weather in os.listdir(os.path.join(path, folder)):\n",
    "            if weather[0] != '.':\n",
    "                for date in os.listdir(os.path.join(path, folder, weather))[-1:]:\n",
    "                    if date[0] != '.':\n",
    "                        for occupied in os.listdir(os.path.join(path, folder, weather, date)):\n",
    "                            if occupied[0] != '.':\n",
    "                                for img in os.listdir(os.path.join(path, folder, weather, date, occupied)):\n",
    "                                    valid_label.append(occupied)\n",
    "                                    valid_img.append(os.path.join(path, folder, weather, date, occupied, img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numoutputs = len(np.unique(train_label))\n",
    "_, t = np.unique(train_label, return_inverse=True)\n",
    "t_train = to_categorical(t, numoutputs)\n",
    "\n",
    "_, t = np.unique(test_label, return_inverse=True)\n",
    "t_test = to_categorical(t, numoutputs)\n",
    "\n",
    "_, t = np.unique(valid_label, return_inverse=True)\n",
    "t_valid = to_categorical(t, numoutputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe to load with tf datagenerator\n",
    "train_df = pd.DataFrame(list(zip(train_img, t_train)), columns =['img_path', 'label'])\n",
    "test_df = pd.DataFrame(list(zip(test_img, t_test)), columns =['img_path', 'label'])\n",
    "valid_df = pd.DataFrame(list(zip(valid_img, t_valid)), columns =['img_path', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 489852 non-validated image filenames.\n",
      "Found 57115 non-validated image filenames.\n",
      "Found 148884 non-validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "img_size = (100, 100)\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "train_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=\"./\",\n",
    "    x_col=\"img_path\",\n",
    "    y_col=\"label\",\n",
    "    #subset=\"training\",\n",
    "    batch_size=1000,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"raw\",\n",
    "    target_size=img_size,\n",
    "    validate_filenames=False\n",
    "    )\n",
    "    \n",
    "valid_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=valid_df,\n",
    "    directory=\"./\",\n",
    "    x_col=\"img_path\",\n",
    "    y_col=\"label\",\n",
    "    #subset=\"training\",\n",
    "    batch_size=1000,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"raw\",\n",
    "    target_size=img_size,\n",
    "    validate_filenames=False\n",
    "    )\n",
    "\n",
    "# test_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "test_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=\"./\",\n",
    "    x_col=\"img_path\",\n",
    "    y_col=\"label\",\n",
    "    #subset=\"training\",\n",
    "    batch_size=1000,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"raw\",\n",
    "    target_size=img_size,\n",
    "    validate_filenames=False\n",
    "    )\n",
    "\n",
    "# fix for bug in keras with 'raw' input in datagenerators:\n",
    "# https://stackoverflow.com/questions/64978209/valueerror-when-trying-to-execute-model-fit-failed-to-convert-a-numpy-array/\n",
    "train_generator._targets = np.stack(train_generator._targets)\n",
    "valid_generator._targets = np.stack(valid_generator._targets)\n",
    "test_generator._targets = np.stack(test_generator._targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-08 16:58:35.791678: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 30000)             0         \n",
      "                                                                 \n",
      " hidden1 (Dense)             (None, 100)               3000100   \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,000,302\n",
      "Trainable params: 3,000,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create neural network\n",
    "model = Sequential()\n",
    "model.add(Input((100, 100, 3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=100, activation='relu', name='hidden1'))\n",
    "# model.add(Dense(units=100, activation='sigmoid', name='hidden2'))\n",
    "# model.add(Dense(units=50, activation='relu', name='hidden3'))\n",
    "# model.add(Dense(units=50, activation='relu', name='hidden4'))\n",
    "model.add(Dense(units=2, activation='softmax', name='output'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer= Adam(learning_rate=0.00001),\n",
    "    loss='mse',\n",
    "    metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490/490 [==============================] - ETA: 0s - loss: 0.0840 - accuracy: 0.9190\n",
      "Epoch 1: saving model to best_simple_nn_weights\n",
      "INFO:tensorflow:Assets written to: best_simple_nn_weights/assets\n",
      "490/490 [==============================] - 1373s 3s/step - loss: 0.0840 - accuracy: 0.9190 - val_loss: 0.0465 - val_accuracy: 0.9586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1674440a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"best_simple_nn_weights\", monitor='accuracy', verbose=1,\n",
    "    save_best_only=False, mode='auto')\n",
    "\n",
    "model.fit(train_generator, validation_data=valid_generator, callbacks=[checkpoint])\n",
    "# save weights\n",
    "model.save('simple_nn_weights2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 588s 4s/step - loss: 0.0363 - accuracy: 0.9720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0362788550555706, 0.9719849228858948]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/ludwig/Documents/College/Semester5/ai2/project/venv/pklot/lib/python3.10/site-packages/keras/engine/training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/ludwig/Documents/College/Semester5/ai2/project/venv/pklot/lib/python3.10/site-packages/keras/engine/training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/ludwig/Documents/College/Semester5/ai2/project/venv/pklot/lib/python3.10/site-packages/keras/engine/training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/ludwig/Documents/College/Semester5/ai2/project/venv/pklot/lib/python3.10/site-packages/keras/engine/training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"/Users/ludwig/Documents/College/Semester5/ai2/project/venv/pklot/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/ludwig/Documents/College/Semester5/ai2/project/venv/pklot/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 100, 100, 3), found shape=(None, 100, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m demo_img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(demo_img, (\u001b[39m100\u001b[39m, \u001b[39m100\u001b[39m))\n\u001b[1;32m      4\u001b[0m demo_img\u001b[39m.\u001b[39mshape\n\u001b[0;32m----> 5\u001b[0m \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39;49mpredict(demo_img))\n",
      "File \u001b[0;32m~/Documents/College/Semester5/ai2/project/venv/pklot/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/y0/db85g6f92g543l1ss46r53040000gn/T/__autograph_generated_file4b6_m0yi.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/ludwig/Documents/College/Semester5/ai2/project/venv/pklot/lib/python3.10/site-packages/keras/engine/training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/ludwig/Documents/College/Semester5/ai2/project/venv/pklot/lib/python3.10/site-packages/keras/engine/training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/ludwig/Documents/College/Semester5/ai2/project/venv/pklot/lib/python3.10/site-packages/keras/engine/training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/ludwig/Documents/College/Semester5/ai2/project/venv/pklot/lib/python3.10/site-packages/keras/engine/training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"/Users/ludwig/Documents/College/Semester5/ai2/project/venv/pklot/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/ludwig/Documents/College/Semester5/ai2/project/venv/pklot/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 100, 100, 3), found shape=(None, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "demo_img = cv2.imread('/Users/ludwig/Documents/College/Semester5/ai2/project2/PKLot/PKLotSegmented_resized/PUC/Rainy/2012-10-23/Occupied/2012-10-23_08_15_50#006.jpg')\n",
    "demo_img = cv2.resize(demo_img, (100, 100))\n",
    "demo_img.shape\n",
    "print(model.predict(demo_img))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('pklot')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Oct 13 2022, 10:18:28) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "135e6675a82798f371aa95a542c2e675d1d47c136c7a33166cb3d7afadac973e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
